---
title: "Midterm Report for JSphere: Classification of The Use of JavaScript on The Web"
subtitle: "Project B for CSci 651 by John Heidemann"
author:
    - name: Steven Hé (Sīchàng)
    - name: "Mentor: Harsha V. Madhyastha"
format:
    html:
        html-math-method: katex
    pdf:
        pdf-engine: latexmk
        papersize: a4
        margin-left: 1in
        margin-right: 1in
        margin-top: 1in
        margin-bottom: 1in
        indent: 2m
        number-sections: true
bibliography: main.bib
csl: acm-sig-proceedings-long-author-list.csl
---

# Weekly Meeting Notes

<!-- Provide a URL to your weekly meeting notes. These need to be accessible to the professor. -->
Link to Weekly Meeting Notes: TODO: add this in private repo.

# Introduction

<!-- Provide an overview of the need you are addressing, what you are doing and plan to do, the novelty and new results of your work, and why this work is interesting to you personally. -->
JavaScript (JS) plays a major role in content delivery on the modern Internet.
For the median webpage, reports show that JS code amounts to
around a quarter of the bytes transferred and JS execution time accounts for
about half of the compute delay.
Despite its significance, it remains understudied why this huge amount of
JS code is used.
While industry observations have argued that most of the JS is unnecessary,
research efforts have instead focused on its security vulnerabilities,
privacy invasions, or performance.
The root cause of all JS issues remains unanswered: Why is so much JS used?
How effective is JS in achieving these purposes?

Better understanding of the use of JS will broadly benefit developers and
users.
Although JS was originally designed for beginner programmers to
script interactive user experiences (UX), it has been adopted for a plethora of
systems tasks, which may explain its high resource usage.
For example, as the popularity of Single-Page Applications (SPAs) rose,
many websites that could otherwise be served as
static HTML instead ship entire SPA frameworks, fetch JSON data from
the server, and convert them into DOM elements.
If we can identify common use of JS, we may guide developers interested in
optimizing their websites, improve general online browsing experience, and
inform future utilization of the Internet for serving Web content.

# Related Work

<!-- Summarize prior work related to yours and describe how your work compares. Include complete citations to the prior work. -->
Prior research has focused on various aspects of JS usage,
including its security vulnerabilities, privacy invasions, and
performance impacts. For instance, Snyder et al.
have explored browser security issues [@snyder2020browser], while Iqbal et al.
have investigated fingerprinting techniques [@iqbal2021fingerprinting].
However, there is a gap in
understanding the fundamental reasons behind the extensive use of JS on
the web.
Our work aims to fill this gap by classifying the functionalities of JS code on
top websites and analyzing their impact on website performance.

# Discussion of Your Work

## Goal

<!-- Describe the goal of your project. -->
The goal of our project is to classify the functionalities of JS code on
the top 1000 websites on the public Web. Specifically, we aim to
categorize each JS file into one or more of the following spheres:
frontend processing, DOM element generation, UX enhancement,
extensional features, or silent.
By analyzing JS browser API calls when interacting with these websites,
we hope to provide insights into the common uses of JS and their impact on
website performance.

## Methodology/Approach

<!-- Explain the methodology or approach you are using in your project. -->
Our approach leverages automated web crawling and API call trace analysis to
understand the behavior of JavaScript on various websites.
The methodology is divided into two main phases: Crawling and Analysis.

### Crawling

We utilized Playwright, a modern web automation tool, to navigate and
interact with web pages. The crawling process involved several critical steps.
**Setup and Configuration.** Initially, we configured Playwright to run in
a Docker container, ensuring a consistent environment.
The container was set up with necessary permissions and configurations to
handle file management and browser interactions efficiently.

**Log Parsing.** A custom log parser library written in Rust was developed to
handle the log format generated by the tests.
This parser was essential for extracting meaningful data from the logs.

**Execution.** The crawler then visited each target website,
performing a series of interactions using a monkey testing approach.
Each site visit was split into separate browser pages to isolate the logs for
different interaction phases.

**Data Management.** Logs and
other data were organized into directories based on the encoded URL of
the site.
Each trial generated specific logs, HAR files, and
JSON files detailing the interactions and reachability of the site.

### Analysis

The analysis phase focused on
interpreting the API call traces collected during the crawling phase.

**Log File Interpretation.** Each log file was analyzed to
separate API calls made before and after the interaction phase.
This distinction was crucial for understanding the behavior of
scripts during different stages of page load and interaction.

**API Call Aggregation.** We aggregated API calls to
identify the most popular APIs overall and per script.
This involved filtering out internal, user-defined, and injected calls to
focus on significant browser APIs.

**Classification.** We manually inspected the most popular APIs to
classify them into categories such as Frontend Processing,
DOM Element Generation, UX Enhancement, and Extensional Features.
This classification helped in understanding the role of different scripts on
the web pages.

## Data Collection

<!-- Detail the data collection process. -->
Data collection was performed through
an automated crawling process using Playwright.
The crawler visited a predefined list of websites, performing interactions and
capturing API call traces. The data collection process involved several steps.

We selected the top 100 websites based on traffic and relevance to our study.
The crawler simulated user interactions on each site,
capturing API call traces during both the page load and interaction phases.
The collected data, including logs, HAR files, and JSON files, were stored in
a structured format for easy access and analysis.

## Results

<!--
For Project B, you should have at least one preliminary result.
If you have other results that are incomplete but expected for Project C,
you can also describe what you plan to do.
-->

### Preliminary Results

<!-- Present any preliminary results you have obtained. If you have other results that are incomplete but expected for Project C, describe what you plan to do. -->
Our preliminary results indicate a tail-heavy distribution of API calls, with
a small percentage of APIs accounting for the majority of calls.
Key findings include that it takes 1.75% (318) of APIs to cover 80% of
all API calls, and 3.74% (678) of APIs to cover 90%.
Many API calls occur before user interactions begin, with DOM and
event APIs dominating the absolute counts.
We identified several "anchor" APIs that strongly indicate specific behaviors,
such as `addEventListener` for Frontend Processing and `createElement` for
DOM Element Generation.

### Expected Results

We expect to further refine our classification heuristics and
improve the accuracy of our script behavior analysis.
Future work will involve developing more sophisticated heuristics to
classify APIs into their respective categories with higher precision.
We also plan to implement log compression and
better data management techniques to handle large volumes of data efficiently.
Additionally, we aim to expand the analysis to a larger set of websites and
explore targeted event listener tests to complement our chaos testing approach.
By continuing to refine our methodology and expand our dataset, we aim to
provide a comprehensive understanding of JavaScript behavior across the web.

# Next Steps for Research Project C

<!-- Describe the next steps for Research Project C. Include a checklist of specific deliverables for Project C:
- Continuing to meet once a week with your mentor
- Continued weekly notes about your progress
- Expected end results (code or experiments)
- Project C report -->

# References {.unnumbered}
<!-- Include a bibliography with at least the citations from the related work section. -->
